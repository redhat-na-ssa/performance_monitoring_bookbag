:guid: %guid%
:user: %user%

:openshift_user_password: %password%
:openshift_console_url: %openshift_console_url%
:openshift_cluster_ingress_domain: %openshift_cluster_ingress_domain%
:user_devworkspace_url: https://devspaces.%openshift_cluster_ingress_domain%
:hyperfoil_web_cli_url: https://%user%-hyperfoil.%openshift_cluster_ingress_domain%
:hyperfoil_benchmark_definition_url: 'https://raw.githubusercontent.com/redhat-na-ssa/workshop_performance-monitoring-apps-template/main/scripts/hyperfoil/summit-load-apps.hf.yaml'
:grafana_url: https://grafana-route-grafana.%openshift_cluster_ingress_domain%

:markup-in-source: verbatim,attributes,quotes
:source-highlighter: highlight.js

= Load Testing, Scaling and Monitoring the Applications

== Logs

Red Hat provides two alternatives for customers looking for logging aggregation solutions: 

- Based on *Elasticsearch, Fluentd and Kibana*: With this solution all logs are streamed from the nodes by Fluentd to Elasticsearch, which in turn stores and index them. Kibana is shipped to visualize the logs. 
- *Grafana Loki* is also provided as an alternative to EFK. Loki is a horizontally scalable, highly available, multi-tenant log aggregation system. While Elasticsearch indexes incoming log records completely during ingestion, Loki only indexes a few fixed labels during ingestion, and defers more complex parsing until after the logs have been stored. This means Loki can collect logs more quickly. As with Elasticsearch, you can query Loki using JSON paths or regular expressions. 

This environment is installed with *Grafana Loki* as the logging aggregation tool. 

With Loki the application logs are available directly from the OpenShift Console. It provides a nice interface to view the logs of your application. This is crucial to troubleshoot issues when something goes wrong. You have multiple options to view the application logs:

- You can connect to a given pod and gets the logs of that specific pod. This is useful to troubleshoot issues with a specific instance of your application. Logs are available at the `Aggregated Logs` tab in the pod view.

image::../imgs/module-5/ocp_console_observe_pod_logs.gif[Pod Agregated Logs view]

[TIP]
====
Don't forget that by default, containers apps scale out to 0 instances when they are not used.
You can use the command `curl https://quarkus-app-${user}-staging.${openshift_cluster_ingress_domain}` or access it directly in your broswer to wake up the container app first if the connections fails.
====

- You can also access the console logs by using the `Observe` menu item, tab `Logs`:

image::../imgs/module-5/ocp_console_observe_logs.gif[Observe | Logs menu]

On `Observe` menu item you can check logs of all namespaces you have access to. In this screen you can filter the logs by message content, pods, containers and severity:

image::../imgs/module-5/ocp_console_observe_pod_logs_filters.gif[Logs filter]

- You may also follow the logs stream in real time from the tab `Logs` of pod screen.

image::../imgs/module-5/ocp_console_pod_stream.gif[Logs stream]

OpenShift Logging is very useful to troubleshoot issues with more complex applications and find out application issues.

[NOTE]
====
To learn more about OpenShift Logging check the following links: 

- https://docs.openshift.com/container-platform/4.12/logging/cluster-logging-loki.html[About LokiStack]
- https://docs.openshift.com/container-platform/4.12/logging/viewing-resource-logs.html[Viewing logs for a resource]
====
